#!/usr/bin/env python3
"""
Script ƒë·∫©y d·ªØ li·ªáu Wikipedia t·ª´ HDFS l√™n Elasticsearch
"""
import json
import subprocess
from elasticsearch import Elasticsearch, helpers

es = Elasticsearch(["http://localhost:9200"])

def ingest_wiki_docs(hdfs_path="/data/wiki/clean/docs", batch_size=500):
    """
    ƒê·∫©y d·ªØ li·ªáu t·ª´ HDFS l√™n Elasticsearch
    
    Args:
        hdfs_path: ƒê∆∞·ªùng d·∫´n HDFS ch·ª©a data clean
        batch_size: S·ªë document m·ªói batch
    """
    cmd = f"hdfs dfs -cat {hdfs_path}/part-*"
    print(f"ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ HDFS: {hdfs_path}")
    
    try:
        proc = subprocess.Popen(
            cmd, 
            shell=True, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.PIPE,
            encoding="utf-8"
        )
        
        def gen_docs():
            count = 0
            errors = 0
            
            for line in proc.stdout:
                line = line.strip()
                if not line:
                    continue
                
                try:
                    doc = json.loads(line)
                    count += 1
                    
                    yield {
                        "_index": "wiki_docs",
                        "_id": doc.get("page_id", count),
                        "_source": {
                            "page_id": doc.get("page_id"),
                            "title": doc.get("title"),
                            "timestamp": doc.get("timestamp"),
                            "categories": doc.get("categories", []),
                            "text": doc.get("text", "")
                        }
                    }
                    
                    if count % 1000 == 0:
                        print(f"  ƒê√£ x·ª≠ l√Ω {count} documents...")
                        
                except json.JSONDecodeError as e:
                    errors += 1
                    if errors <= 5:
                        print(f"  ‚ö† L·ªói JSON (d√≤ng {count + errors}): {str(e)[:50]}...")
                except Exception as e:
                    errors += 1
                    if errors <= 5:
                        print(f"  ‚ö† L·ªói kh√°c: {str(e)[:50]}...")
            
            print(f"\nüìä T·ªïng k·∫øt:")
            print(f"  - Documents h·ª£p l·ªá: {count}")
            print(f"  - L·ªói: {errors}")
        
        # Bulk insert v√†o Elasticsearch
        success, failed = helpers.bulk(
            es, 
            gen_docs(), 
            chunk_size=batch_size,
            raise_on_error=False,
            stats_only=True
        )
        
        print(f"\n‚úì Ho√†n th√†nh!")
        print(f"  - Th√†nh c√¥ng: {success}")
        print(f"  - Th·∫•t b·∫°i: {failed}")
        
        # Ki·ªÉm tra s·ªë l∆∞·ª£ng documents trong index
        count = es.count(index="wiki_docs")["count"]
        print(f"  - T·ªïng documents trong ES: {count}")
        
    except subprocess.CalledProcessError as e:
        print(f"‚ùå L·ªói HDFS command: {e}")
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")

if __name__ == "__main__":
    print("=" * 60)
    print("INGEST WIKIPEDIA DATA TO ELASTICSEARCH")
    print("=" * 60)
    ingest_wiki_docs()
