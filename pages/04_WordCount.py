#!/usr/bin/env python3
"""
WordCount Page - Ph√¢n t√≠ch t·∫ßn su·∫•t t·ª´ kh√≥a
"""
import streamlit as st
import pandas as pd
from utils.es_client import get_es_client

# Page config
st.set_page_config(
    page_title="WordCount - Wikipedia",
    page_icon="üî§",
    layout="wide"
)

# Get ES client
es = get_es_client()

# Header
st.title("Ph√¢n t√≠ch t·∫ßn su·∫•t t·ª´ kh√≥a")
st.markdown("---")

@st.cache_data(ttl=3600)
def load_wordcount_data():
    """Query wordcount t·ª´ Elasticsearch"""
    try:
        query = {
            "size": 10000,
            "_source": ["word", "count"],
            "sort": [{"count": "desc"}]
        }
        
        response = es.search(index="wiki_wordcount", body=query)
        
        data = []
        for hit in response["hits"]["hits"]:
            source = hit["_source"]
            data.append({'word': source['word'], 'count': source['count']})
        
        if not data:
            return None, "Kh√¥ng c√≥ d·ªØ li·ªáu"
        
        df = pd.DataFrame(data)
        return df, None
        
    except Exception as e:
        return None, str(e)

# Load data
with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu..."):
    df_wc, error = load_wordcount_data()

if error:
    st.error(f"L·ªói: {error}")
    st.info("Ch·∫°y `python elasticsearch/index_all_data.py` ƒë·ªÉ index d·ªØ li·ªáu")
elif df_wc is not None and len(df_wc) > 0:
    
    # Overview metrics
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("T·ªïng t·ª´ kh√°c nhau", f"{len(df_wc):,}")
    with col2:
        st.metric("T·ªïng t·ª´ xu·∫•t hi·ªán", f"{df_wc['count'].sum():,}")
    with col3:
        st.metric("T·ª´ ph·ªï bi·∫øn nh·∫•t", f"{df_wc.iloc[0]['word']}")
    
    st.markdown("---")
    
    # Filters
    col_f1, col_f2, col_f3 = st.columns(3)
    
    with col_f1:
        top_n = st.slider("S·ªë t·ª´ hi·ªÉn th·ªã:", 10, 200, 50)
    
    with col_f2:
        min_count = st.number_input("T·∫ßn su·∫•t t·ªëi thi·ªÉu:", 1, 10000, 100)
    
    with col_f3:
        search_word = st.text_input("T√¨m t·ª´ c·ª• th·ªÉ:", "")
    
    # Apply filters
    df_filtered = df_wc[df_wc['count'] >= min_count]
    
    if search_word:
        df_filtered = df_filtered[df_filtered['word'].str.contains(search_word, case=False, na=False)]
    
    df_filtered = df_filtered.head(top_n)
    
    st.markdown("---")
    
    # Chart
    st.subheader(f"Top {len(df_filtered)} t·ª´ kh√≥a")
    
    if len(df_filtered) > 0:
        st.bar_chart(df_filtered.set_index('word')['count'], height=500)
        
        st.markdown("---")
        
        # Table
        st.subheader("B·∫£ng chi ti·∫øt")
        
        df_display = df_filtered.rename(columns={'word': 'T·ª´', 'count': 'S·ªë l·∫ßn xu·∫•t hi·ªán'})
        
        st.dataframe(
            df_display,
            use_container_width=True,
            height=400
        )
        
        # Download
        csv = df_display.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            "T·∫£i xu·ªëng CSV",
            csv,
            "wordcount.csv",
            "text/csv",
            use_container_width=True
        )
    else:
        st.warning("Kh√¥ng c√≥ t·ª´ n√†o ph√π h·ª£p v·ªõi b·ªô l·ªçc")
        
else:
    st.info("Ch∆∞a c√≥ d·ªØ li·ªáu. Ch·∫°y `python elasticsearch/index_all_data.py`")
