#!/usr/bin/env python3
"""
Search Page - T√¨m ki·∫øm to√†n vƒÉn Wikipedia
"""
import streamlit as st
from datetime import datetime
from utils.es_client import get_es_client

# Page config
st.set_page_config(
    page_title="Search - Wikipedia",
    page_icon="üîç",
    layout="wide"
)

# Get ES client
es = get_es_client()

# Header
st.title("T√¨m ki·∫øm Wikipedia")
st.markdown("---")

# Input form
col1, col2, col3 = st.columns([4, 2, 1])

with col1:
    query_text = st.text_input(
        "Nh·∫≠p t·ª´ kh√≥a t√¨m ki·∫øm:",
        placeholder="V√≠ d·ª•: H√† N·ªôi, H·ªì Ch√≠ Minh, l·ªãch s·ª≠ Vi·ªát Nam...",
        key="search_input"
    )

with col2:
    search_type = st.selectbox(
        "Lo·∫°i t√¨m ki·∫øm:",
        ["Ti√™u ƒë·ªÅ + N·ªôi dung", "Ch·ªâ ti√™u ƒë·ªÅ", "Ch·ªâ n·ªôi dung"],
        key="search_type"
    )

with col3:
    num_results = st.number_input(
        "S·ªë k·∫øt qu·∫£:",
        min_value=5,
        max_value=100,
        value=10,
        step=5,
        key="num_results"
    )

# Advanced options
with st.expander("T√πy ch·ªçn n√¢ng cao"):
    col_adv1, col_adv2 = st.columns(2)
    with col_adv1:
        use_fuzzy = st.checkbox("T√¨m ki·∫øm m·ªù (fuzzy)", value=True, help="Cho ph√©p t√¨m c√°c t·ª´ t∆∞∆°ng t·ª±")
    with col_adv2:
        highlight = st.checkbox("Highlight t·ª´ kh√≥a", value=True, help="ƒê√°nh d·∫•u t·ª´ kh√≥a trong k·∫øt qu·∫£")

# Search button
if st.button("T√¨m ki·∫øm", type="primary", use_container_width=True):
    if query_text:
        with st.spinner("ƒêang t√¨m ki·∫øm..."):
            try:
                # X√¢y d·ª±ng query
                if search_type == "Ti√™u ƒë·ªÅ + N·ªôi dung":
                    query_body = {
                        "multi_match": {
                            "query": query_text,
                            "fields": ["title^3", "text"],
                            "fuzziness": "AUTO" if use_fuzzy else "0"
                        }
                    }
                elif search_type == "Ch·ªâ ti√™u ƒë·ªÅ":
                    query_body = {
                        "match": {
                            "title": {
                                "query": query_text,
                                "fuzziness": "AUTO" if use_fuzzy else "0"
                            }
                        }
                    }
                else:
                    query_body = {
                        "match": {
                            "text": {
                                "query": query_text,
                                "fuzziness": "AUTO" if use_fuzzy else "0"
                            }
                        }
                    }
                
                # Search request
                search_request = {
                    "query": query_body,
                    "size": num_results
                }
                
                # Add highlight
                if highlight:
                    search_request["highlight"] = {
                        "fields": {
                            "title": {"pre_tags": ["<mark>"], "post_tags": ["</mark>"]},
                            "text": {
                                "fragment_size": 200,
                                "number_of_fragments": 3,
                                "pre_tags": ["<mark>"],
                                "post_tags": ["</mark>"]
                            }
                        }
                    }
                
                # Execute search
                response = es.search(index="wiki_docs", body=search_request)
                
                hits = response["hits"]["hits"]
                total = response["hits"]["total"]["value"]
                took = response["took"]
                
                st.success(f"T√¨m th·∫•y **{total:,}** k·∫øt qu·∫£ trong **{took}ms**")
                st.markdown("---")
                
                # Display results
                if hits:
                    for i, hit in enumerate(hits, 1):
                        source = hit["_source"]
                        score = hit["_score"]
                        
                        with st.container():
                            st.markdown(f"### {i}. {source.get('title', 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ')}")
                            
                            # Metadata
                            meta_cols = st.columns(4)
                            with meta_cols[0]:
                                st.caption(f"ƒêi·ªÉm: {score:.2f}")
                            with meta_cols[1]:
                                timestamp = source.get('timestamp', 'N/A')
                                if timestamp and timestamp != 'N/A':
                                    try:
                                        dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                                        timestamp = dt.strftime('%Y-%m-%d %H:%M')
                                    except:
                                        pass
                                st.caption(f"Ng√†y: {timestamp}")
                            with meta_cols[2]:
                                num_cats = len(source.get('categories', []))
                                st.caption(f"Danh m·ª•c: {num_cats}")
                            with meta_cols[3]:
                                page_id = source.get('page_id', 'N/A')
                                st.caption(f"ID: {page_id}")
                            
                            # Highlight or snippet
                            if highlight and "highlight" in hit:
                                if "title" in hit["highlight"]:
                                    st.markdown(f"**Ti√™u ƒë·ªÅ kh·ªõp:** {hit['highlight']['title'][0]}", unsafe_allow_html=True)
                                
                                if "text" in hit["highlight"]:
                                    st.markdown("**N·ªôi dung kh·ªõp:**")
                                    for fragment in hit["highlight"]["text"][:2]:
                                        st.markdown(f"> ...{fragment}...", unsafe_allow_html=True)
                            else:
                                text = source.get('text', '')
                                if text:
                                    snippet = text[:300] + "..." if len(text) > 300 else text
                                    st.markdown(f"**N·ªôi dung:** {snippet}")
                            
                            # Categories
                            categories = source.get('categories', [])
                            if categories:
                                cats_display = categories[:8]
                                remaining = len(categories) - len(cats_display)
                                cats_str = ", ".join(f"`{c}`" for c in cats_display)
                                if remaining > 0:
                                    cats_str += f" _(+{remaining} danh m·ª•c kh√°c)_"
                                st.markdown(f"**Danh m·ª•c:** {cats_str}")
                            
                            st.markdown("---")
                else:
                    st.info("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ ph√π h·ª£p.")
                    
            except Exception as e:
                st.error(f"L·ªói: {str(e)}")
                st.info("ƒê·∫£m b·∫£o Elasticsearch ƒëang ch·∫°y v√† index 'wiki_docs' ƒë√£ ƒë∆∞·ª£c t·∫°o.")
    else:
        st.warning("Vui l√≤ng nh·∫≠p t·ª´ kh√≥a t√¨m ki·∫øm!")
